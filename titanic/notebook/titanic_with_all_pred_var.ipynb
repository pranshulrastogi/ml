{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "import os\n",
    "import pandas as pd\n",
    "train_csv = os.path.join(\"..\",\"dataset\",\"train.csv\")\n",
    "test_csv = os.path.join(\"..\",\"dataset\",\"test.csv\")\n",
    "\n",
    "# load the csv into dataframe\n",
    "titanic_train = pd.read_csv(train_csv)\n",
    "titanic_test = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "### 12 columns, 1 target and 11 predictor\n",
    "### seems not useful columns: PassengerId, Name, Ticket\n",
    "### Cabin contains 90% null values, better to drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out target and predictors\n",
    "y = titanic_train['Survived']\n",
    "X = titanic_train.copy()\n",
    "X.drop(['Survived'], axis=1, inplace=True)\n",
    "# remove the columns that seems unuseful to the problem\n",
    "useless_cols = ['PassengerId','Name', 'Ticket','Cabin']\n",
    "X.drop(useless_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y, random_state=0, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the train and testing data further to get missing values\n",
    "### Age has some missing values approx 10% and Embarked have very few missing values\n",
    "### Age need to be imputed with mean value and Embarked with mode\n",
    "### in test split, only Age has missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical cols are: ['Sex', 'Embarked']\n",
      "numerical cols are: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n"
     ]
    }
   ],
   "source": [
    "# handle the missing values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "ni = SimpleImputer(strategy='mean')\n",
    "ci = SimpleImputer(strategy='most_frequent')\n",
    "X_train_i = X_train.copy()\n",
    "X_test_i = X_test.copy()\n",
    "\n",
    "cat_cols = [col for col in X_train.columns if X_train[col].dtype=='object']\n",
    "num_cols = [col for col in X_train.columns if X_train[col].dtype != 'object']\n",
    "print(\"Categorical cols are: {}\".format(cat_cols))\n",
    "print(\"numerical cols are: {}\".format(num_cols))\n",
    "\n",
    "X_train_i.loc[:,cat_cols] = ci.fit_transform(X_train_i[cat_cols])\n",
    "X_test_i.loc[:,cat_cols] = ci.transform(X_test_i[cat_cols])\n",
    "\n",
    "X_train_i.loc[:,num_cols] = ni.fit_transform(X_train_i[num_cols])\n",
    "X_test_i.loc[:,num_cols] = ni.transform(X_test_i[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the missing values are being taken care of, lets focus on encoding categorical cols\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X_train_ie = X_train_i.copy()\n",
    "X_test_ie = X_test_i.copy()\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "ohe_train = pd.DataFrame(ohe.fit_transform(X_train_ie[cat_cols]))\n",
    "ohe_test = pd.DataFrame(ohe.transform(X_test_ie[cat_cols]))\n",
    "# X_train_ie.index = X_train_i.index\n",
    "# X_test_ie.index = X_test_i.index\n",
    "ohe_train.index = X_train_ie.index\n",
    "ohe_test.index = X_test_ie.index\n",
    "\n",
    "# drop cat cols from dataset and add encoded\n",
    "X_train_ie.drop(cat_cols,axis=1, inplace=True)\n",
    "X_test_ie.drop(cat_cols, axis=1, inplace=True)\n",
    "\n",
    "X_train_p = pd.concat([X_train_ie,ohe_train], axis=1)\n",
    "X_test_p = pd.concat([X_test_ie, ohe_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to model the class\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def rfe_eval_score(n_estimators, X_train, X_test, y_train, y_test):\n",
    "    model = RandomForestRegressor(random_state=0, n_estimators=n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    error = mean_absolute_error(y_test,predictions)\n",
    "    print(y_test.head())\n",
    "    print(predictions[:5])\n",
    "    return error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495    0\n",
      "648    0\n",
      "278    0\n",
      "31     1\n",
      "255    1\n",
      "Name: Survived, dtype: int64\n",
      "[0.364 0.019 0.008 0.73  0.184]\n",
      "0.23129080616684955\n"
     ]
    }
   ],
   "source": [
    "score = rfe_eval_score(500, X_train_p, X_test_p, y_train, y_test)\n",
    "print(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
